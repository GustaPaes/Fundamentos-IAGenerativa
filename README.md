# Projetos de IA Generativa

Este repositÃ³rio reÃºne trÃªs aplicaÃ§Ãµes demonstrativas de inteligÃªncia
artificial generativa construÃ­das como parte de desafios prÃ¡ticos. Cada
projeto Ã© independente e pode ser executado isoladamente; todos usam a
mesma estrutura bÃ¡sica de cliente para LLMs e podem funcionar com a API
do OpenAI ou de outros provedores.

## ğŸ“ VisÃ£o Geral dos Projetos

| Projeto     | DescriÃ§Ã£o rÃ¡pida                                                 |
|-------------|------------------------------------------------------------------|
| **projeto01** | Cliente simples de chat com OpenAI; foco em aprendizado de integraÃ§Ã£o e prompts.         |
| **projeto02** | Classificador de mensagens de clientes com robustez em produÃ§Ã£o (JSON, validaÃ§Ã£o, fallback, relatÃ³rios). |
| **projeto03** | Sistema RAG (recuperaÃ§Ã£o augmentada por geraÃ§Ã£o) usando base de conhecimento; inclui proteÃ§Ã£o contra prompt injection e vetor store em memÃ³ria. |

### projeto01 â€“ Cliente de Chat
Um script mÃ­nimo que se conecta Ã  API da OpenAI (`gpt-4o-mini` por
default), envia prompts e exibe respostas. Ideal para entender como
configurar o ambiente, definir mensagens de sistema/usuÃ¡rio e lidar com
parÃ¢metros como temperatura e max tokens.

Arquivos principais:
- `main.py` â€“ interface de linha de comando.
- `requirements.txt` â€“ depende apenas de `openai` e `python-dotenv`.

### projeto02 â€“ Classificador de Mensagens
Utiliza um LLM para categorizar mensagens de cliente em classes como
"reclamaÃ§Ã£o", "elogio", etc. ContÃ©m validaÃ§Ã£o robusta do JSON retornado
pelo modelo, proteÃ§Ã£o contra prompt injection e mecanismo de fallback
quando a API falha. Gera relatÃ³rios Markdown com estatÃ­sticas de
desempenho e inclui uma suite de testes (`pytest`).

Arquivos-chave:
- `classifier.py` â€“ lÃ³gica de classificaÃ§Ã£o e fallback.
- `validator.py` â€“ parsing/validaÃ§Ã£o de JSON e injeÃ§Ã£o de prompts.
- `main.py` â€“ executa vÃ¡rias repetiÃ§Ãµes e emite `relatorio.md`.
- `tests/` â€“ casos de testes que nÃ£o dependem da API.

### projeto03 â€“ RAG com ProteÃ§Ãµes
ConstruÃ§Ã£o mais avanÃ§ada que combina embeddings e busca por similaridade
enquanto protege contra tentativas de instruir o modelo com prompts
maliciosos. Suporta mÃºltiplos provedores (OpenAI ou Groq), embeddings
locais quando a cota OpenAI nÃ£o estÃ¡ disponÃ­vel, e leitura de arquivos
TXT/PDF/DOCX na pasta `conhecimento/`.

Destaques:
- VetorizaÃ§Ã£o local (hash de palavras) para operaÃ§Ã£o offline.
- RecuperaÃ§Ã£o hÃ­brida (vetorial + lÃ©xica) para maior precisÃ£o.
- Prompt de sistema rigoroso e validaÃ§Ã£o JSON melhorada.
- Estrutura de leitura multi-formato em `retriever.py`.


## ğŸ“‚ Estrutura do RepositÃ³rio

```
â”œâ”€â”€ projeto01/          # Cliente de chat bÃ¡sico
â”‚   â”œâ”€â”€ main.py         # Script principal
â”‚   â””â”€â”€ requirements.txt # DependÃªncias
â”‚
â”œâ”€â”€ projeto02/          # Classificador de mensagens com validaÃ§Ã£o
â”‚   â”œâ”€â”€ main.py          # Classificador principal e geraÃ§Ã£o de relatÃ³rios
â”‚   â”œâ”€â”€ classifier.py    # LÃ³gica de classificaÃ§Ã£o com fallbacks
â”‚   â”œâ”€â”€ llm_client.py    # Cliente LLM abstrato
â”‚   â”œâ”€â”€ validator.py     # ValidaÃ§Ã£o, parser JSON e fallback seguro
â”‚   â”œâ”€â”€ requirements.txt # DependÃªncias (incluindo pytest)
â”‚   â”œâ”€â”€ relatorio.md     # RelatÃ³rio de anÃ¡lises gerado pelo script
â”‚   â””â”€â”€ tests/           # Suite de testes automatizados (pytest)
â”‚
â””â”€â”€ README.md          # Este arquivo
```

---

## ğŸš€ Como ComeÃ§ar

1. Clone ou acesse o repositÃ³rio
2. Navegue atÃ© o projeto desejado
3. Instale as dependÃªncias: `pip install -r requirements.txt`
4. Configure sua chave de API OpenAI em um arquivo `.env`
5. Execute: `python main.py`

---

## ğŸ”§ Requisitos

- Python 3.8+
- Chave de API OpenAI
- DependÃªncias listadas em `requirements.txt`

---

## ğŸ“ Notas Importantes

- O repositÃ³rio contÃ©m trÃªs projetos independentes, cada um com um foco diferente (chat, classificaÃ§Ã£o e RAG).
- Os componentes incluem validaÃ§Ã£o de JSON, proteÃ§Ã£o contra prompt injection e fallback seguro para APIs.
- Todos os scripts suportam execuÃ§Ã£o em modo de teste sem depender da API real, Ãºtil para desenvolver offline.
- Se nÃ£o houver chave OpenAI ou a cota estiver esgotada, o `projeto03` utiliza embeddings locais para continuar operando.
- Os projetos podem ser usados como base para experimentos pessoais e portfÃ³lio pÃºblico.
- O cliente LLM usa `max_retries=0` para falhar rapidamente em caso de erros de quota, evitando longos bloqueios.

